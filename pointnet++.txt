PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space

Introduction
    - Interested in analyzing geometric point sets which are collections of points in a Euclidean space
        > particularly, interested in point cloud captured by 3D scanners 
    - As a set, such data has to be invariant to permutations of its members 
    - Additionally, distance metric defines local neighborhoods that may exhibit different properties 
        > EG density and other attributes of points may not be uniform across different locations 
            - in 3D scanning, density variability can come from perspective effects, radial density varaition, motion ect
    - Basic idea of PointNet is to learn a spatial encoding of each point and then aggregate all individual point features to a global point cloud signature 
        > however, by design, PointNet does not capture local structure induced by the metric 
        > Exploiting local structure has proven to be important for the success of convolutional architectures
            - The ability to abstract local patterns along the hierarchy allows better generalizability to unseen cases 
    - PointNet++ is a hierarchical neural netowrk that processes a set of points sampled in a metric space in a hierarchical fashion 
    - General Idea of PointNet++ is simple:
        1: first partition set of points into overlapping local features capturing fine geometric structures from small neighborhoods
        2: these local features are further grouped into larger units and processed to produce higher level features 
        3: this is repeated unitl features of the whole point set is obtained 

    - Design of PointNet++ aims to address 2 issues:
        1: how to generate the partioning of the point set?
        2: how to abstract sets of points or local features through local feature learner 
        > these 2 issues are correlated bc the partitioning of the point set has to produce common structures across partitions
            - this is so that weights of local feature learners can be shared across partitions
        > PointNet is used as local feature learner as it is an effective architecture to process an unordered set of points for semantic feature extraction
            - it is also robust to input data corruption 
            - PointNet helps abstract sets of local points or features into higher level representations 
                > in this view, PointNet++ applies PointNet recursively on a nested partiioning of the input set
    - Issue of how to generate overlapping partitioning of a point set still remains 
        > Each partition is defined as a neighborhood ball in the underlying Euclidean space, whose parameters include centroid location and scale 
        > The centroids are selected among input point set by a farthest point sampling algo to ensure even coverage of whole set
        > Local receptive fields are dependent on both the input data and the metric, making it more efficient and effective 
    - Furthermore, deiciding the appropriate scale of local neighborhood balls is a more challenging problem (intriguing too!)
        > this is due to the entanglement of feature scale and non-uniformity of input point set 
            - input point set are assumed to potentially have variable density (common IRL) 
            - thus input point are different from CNN inputs which can be viewed as data defined on regular grids with uniform constant density 
                > a counterpart to local partition scale is the size of kernel in CNN
                > however, unlike in CNN where small kernel size can be effective, small neighborhod might not be effective for partitioning
                    - this may be due to sampling deficiency (non-uniformity of points), Causing PointNet to not be able to capture patterns robustly
Significant Contribution:
    - PointNet++ leverages neighborhoods at multiple scales to achieve both robustness and detail capture 
        > Assisted with random input dropout during training, the network learns to adaptively weight patterns detected at different scales 
        and combine multi-scale features according to input data
Problem Statement 
    - Suppose that X = (M,d) is a discrete metric space whose metric is inherited from a Euclidean space R^n
        > M is a subset of this Euc. space, or a set of points and d is the distance metric 
        > density of M is non-uniform 
    - we are inteterested in learning set functions f that take such X as the input and produce information of semantic interest regarding X.
        > in practice, such f can be 
            1: a classification function that assigns a label to X 
            2: a segmentation function that assigns a per point label to each member of M

Method
    > PointNet++ is basically an extension of PointNet with added hierarchical structure
    > As such, we first review PointNet, then introduce a basic extention of PointNet with hierichical strucutre, and finally propose PointNet++ that can robustly learn features even in non-uniformity sampled point sets

    1: Review of PointNet: A Universal Continuous Set Function Approximator
        - Given an unordered set of points {x_1 ... x_n} with x_i in R^d, one can define a set function F : X -> R that maps a set of points to a vector
            > f(x_1 ... x_n) = phi(MAX_[i = 1:n]{ h(x_i) }), where phi and h are MLPs 
            > set function is invariant to input point permutation and can arbitrarily approximate any continuous set function
            > Response of h(.) can be thought of as the spatial encodding of a point (PointNet)
    2: Hierarchical Point Set Feature Learning 
        > In PointNet, a single max pooling is used to aggregate the whole point set 
        > our new architecture builds a hierarchical grouping of points and progressively abstract larger and larger local regions along the hierarchy
            - this architecture is composed by a number of set abstraction levels 
            - At each level, a set of points is processed and abstracted to produce a new set with fewer elements 
            - The set abstraction level is made of 3 key elements:
                1: Smapling Layer
                    > this layer selects a set of points from input points, which defines the centroid of local regions 
                    > More formaly, given input point {x_1 ... x_n}, we use iterative farthest point sampling to choose a subset of points {x_i1 ... x_im}
                      such that x_ij is the most distant point (in metric distance) from set {x_i1 ... x_ij-1} with regards to the rest points 
                        - Compared with random sampling, it has better coverage of the entire point set given the same number of centroids 
                        - In contrast with CNNS that scan the vector sace agnostic of data distribution, this sampling strategy generates receptive fields 
                          in a data dependent manner 
                2: Grouping Later 
                    > this layer constructs local region sets by finding "neighboring" points around the centroids 
                    > The input to this layer is:
                        1: a point set of size N x (d + C), d is the dimension coords , N is num of points and C is dim of point feature
                        2: coordinates of a set of centroids of size N_ x d 
                    > outputs are groups of point set of size N_ x K x (d + C), where each group corresponds to a local region and K is the num of points in 
                      the neighborhood of centroid points 
                        * K varies across groups, but the suceeding PointNet layer is able to convert a flexible number of points into a fixed length local region feature vector 
                    > In CNN, a local region of a pixel consist of pixels with array indices within certain Manhattan distance (kernel size) of the pixel 
                        - In a point set sampled from metric space, the neighbourhood of a point is defined by metric distance 
                        - Ball query finds all points that are within radius to the query point (an upper limit of K is set in implementaion for comp tracibility)
                            > an alternative range query is K nearest neighborhood search which finds a fixed number of neighboring points 
                            > Compared with kNN, ball query's local neighborhood guarantees a fixed region scale, thus making local region feature more generalisable across space
                                - this is preffered for tasks requiring local pattern recognition (semantic point labelling)                            
                3: PointNet Layer 
                    > this layer uses a mini-PointNet to encode local region patterns into faeture vectors 
                    > the input to this layer are N_ local regions of points with data size N_ x K x (d + C)
                    > each local region in the output is abstracted by its centroid and local feature that encodes the centroid's neighborhood 
                    > output data size is N_ x (d + C_)
                    > The coordinates of points in a local region are firstly translated into a local frame relative to the centroid point: x^(j)_i = x^(j)_i - x'^(j) for i = 1 ... K and j = 1 ... d
                      where x' is the coordinate of the centroid 
                        * as oppose to this translation, a sine/cosine encoding is used in the instant policy paper! 
                        - PointNet is used as the basic building block for local pattern learning 
                        - by using relative coords together with point features, we can capture point-to-point relations in the local region 
                * Potentially Non-Euc can be used to replace any of these 3 layers, maybe the PointNet layer 
            - TLDR the set abstraction level taks an N x (d+C) matrix as input that is from N points with d-dim coords and C-dim point features
              and outputs an N_ x ( d+C_ ) matrix of N_ subsampled points with d-dim coords and C_-dim feature vectors summarizing local context 
    3: Robust Feature Learning under Non-Uniform Sampling Density
        - Non-Uniformity introduces a significant challenge for point set feature learning 
            > Features learned in dense data may not generalise to sparsely sampled regions 
            > Consequently, models trained for sparse point cloud may not recognise fine-grained local structures
        - Ideally, we want to inspect into a point set to capture finest details in densely sampled regions 
            > But such close inspection is prohibited at low density areas as local patterns may be corrupted by smapling deficiency
            > In such case, we should look for larger scale patterns in greater viscinity 
                - this is achieved with a density adaptive PointNet layer that learn to combine features from regions of different scales when input sampling density changes (aka PointNet++)
        - In the Naive model, each abstraction level contains grouping and feature extraction of a single scale 
            > in PointNet++, each abstraction level extracts multiple scales of local patterns and combine them intellligently according to local point densities 
            > in terms of grouping local regions and combining features from different scales, we propose 2 types of density adaptive layers 
                1: Multi-scale Grouping 
                    - This is a naive implementation, where grouping layers are applied with different scales, followed by according PointNets to extract features of each scale
                    - Features at different scales are concatenated to form a multi-scale feature
                    - A network is then trained to learn an optimised strategy to combine the multi-csale features
                        > this is done by randomly dropping out input points with a randomised probability for each instance (aka random input dropout)
                        > Specifically, for each training point set, we choose a dropout ratio \theta uniformly sample from [0,p] where p <= 1 (\theta in [0:p])
                            - For each point we randomnly drop a point with probability \theta
                            - In practice we set p = 0.95 to avoid generating to avoid generating empty point sets 
                        > In doing so we present the network with training sets of various sparsity (induced by randomness in \theta) and varying uniformity (induced by randomness in dropout)
                    - During testing, all available points are kept 
                    - This approach is computationally expensive since it runs local PointNet at large scale neighborhood for every centroid point
                        > In particular, since the number of centroid points is usually quite large at the lowest level, the time cost is significant 
                            * so thats why its called a 'ball model'
                2: Multi-resolution grouping 
                    - Due to the computation cost of MSG, the MRG approach is used, where expensive computations are avoided but the ability to adaptively aggregate information according to the 
                      distributional properties of points is kept
                    - Features of a region at some level L_i is a concatenation of 2 vector     
                        > One vector is obtained by summarizing the features at each subregion from the lower level L_i-1 using the set abstraction level
                        > the other vector is the feature that is obtained by directly processing all raw points in the local region using a single PointNet
                    - When density of a local region is low, the first vector may be less reliable than the second vector, since the subregion in computing the first vector contains even sparser
                      points and suffers more from sampling deficiency
                        > In such a case, the second vector should be weighted higher
                    - On the other hand, when the density of a local region is high, the first vector provides information of finer details since it possesses the ability to inspect at higher resolution
                      recursively in lower levels 
                    * compared with MSG, this approach is computationally more efficient since we avoid the feature extraction in large scale neighborhoods at lowest levels (Kinda like divide-and-conquer/memoisation)
    > Point Feature Propagation for Set segmentation
        - In the set abstraction layer, the original point set is subsampled 
            > However in set segmentation task like semantic point labelling, we want to obtain point features for all the original points
        - One solution is to alway sample all points as centroids in all set abstraction levels
            > but this results in high computation cost 
        - Another way is to propagate features from subsampled points to the original points 
            > To do this, a hierarchical propagation strategy with distance based interpolation and across level skip links 
                - In a feature propagation level, we propagate point features from N_l x (d + C) points to N_l-1 points, where N_l-1 and N_l (N_l <= N_l-1) are point set size of input and 
                  output of set abstraction level l 
                    > Feature propagation is achieved by interpolating feature values f of N_l points at coordinates of the N_l-1 points 
                        - Among many choices for interpolation, we use inverse distance weighted averaged based on kNN:
                            > f^j(x) = \frac{sum[i=1:k] w_i(x) f^j_i} {sum[i=1:k] w_i(x)}, where w_i(x) = 1/d(x,x_i)^p, j = 1 ... C [ by default, p = 2, k = 3]
                        - the interpolated features on N_l-1 points are then concatenated with skip linked point features from the set abstraction level 
                        - then the concatenated features are passed through a "unit pointnet", which is similar to one-by-one convolution in CNNs
                            > A few shared fully connected and ReLU layers are applied to update each point's feature vector
                        - The process is repeated until we have propagated features to the original set of points 


            